{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39ca9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv src/.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31a7a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/kushagrasharma/coding/hormozlab/src')\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import kneighbors_graph, NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.AutoEncoder import AE, Encoder, Decoder\n",
    "from src.Binary2LatentNN import Binary2LatentNN\n",
    "from src.Binary2TranscriptomeNN import Binary2TranscriptomeNN\n",
    "from src.utils import *\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b224920",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.environ.get(\"DATA_DIR\")\n",
    "MODELS_DIR = os.environ.get(\"MODELS_DIR\")\n",
    "\n",
    "binary_matrix_filepath = MODELS_DIR + 'binary_matrix.npy'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abaf062",
   "metadata": {},
   "source": [
    "We will now display the results of our analyses. As a reminder, the goal is to determine the best method for reconstructing cell state / transcriptome data from a low-dimensional, binary combination of genes that is experimentally feasible to measure. Previous analyses have found that the particular genes and combinations that are being taken do not have a large impact on reconstruction accuracy, thus we use a preselected random matrix for all our computations, with the experimentally feasible parameters $50$ genes per combination with $10$ total binary combinations. \n",
    "\n",
    "Our primary evaluation metric is the cross-entropy between the reconstructed distribution and the ground truth distribution; the Gaussian analogue we previously constructed. Our secondary evaluation metric is the mean squared error between the ground truth transcriptome and the reconstructed transcriptome. We determine the reconstructed transcriptome by taking a weighted average of the training cells as indicated by the reconstructed distribution.\n",
    "\n",
    "For cells not in the training set that are thereby lacking a ground truth measurement (e.g. the validation and test sets), we use the closest cell in the training set to the given cell to construct a ground truth distribution to evaluate in comparison to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ad625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading Data\n",
    "binary_matrix = torch.tensor(np.load(binary_matrix_filepath)).float()\n",
    "\n",
    "train_full = pd.read_csv(DATA_DIR + 'scvi_train_set_gapdh.csv', header=None).to_numpy()\n",
    "test_full = pd.read_csv(DATA_DIR + 'scvi_test_set_gapdh.csv', header=None).to_numpy()\n",
    "valid_full = pd.read_csv(DATA_DIR + 'scvi_valid_set_gapdh.csv', header=None).to_numpy()\n",
    "\n",
    "train_umap = pd.read_csv(DATA_DIR + 'train_coords.csv', header=None).to_numpy()\n",
    "test_umap = pd.read_csv(DATA_DIR + 'test_coords.csv', header=None).to_numpy()\n",
    "valid_umap = pd.read_csv(DATA_DIR + 'valid_coords.csv', header=None).to_numpy()\n",
    "\n",
    "train_tensor = torch.tensor(train_full).float()\n",
    "valid_tensor = torch.tensor(valid_full).float()\n",
    "test_tensor = torch.tensor(test_full).float()\n",
    "\n",
    "train_binary_tensor = torch.matmul(train_tensor, binary_matrix)\n",
    "valid_binary_tensor = torch.matmul(valid_tensor, binary_matrix)\n",
    "test_binary_tensor = torch.matmul(test_tensor, binary_matrix)\n",
    "\n",
    "gaussian_train = np.load(DATA_DIR + 'truncated_gaussian_sigma_10thNN.npy')\n",
    "\n",
    "closest_cell_to_valid = np.load(DATA_DIR + 'closest_cell_to_valid.npy')\n",
    "closest_cell_to_test = np.load(DATA_DIR + 'closest_cell_to_test.npy')\n",
    "\n",
    "gaussian_valid = np.apply_along_axis(lambda x: gaussian_train[x,:], 0, closest_cell_to_valid)\n",
    "gaussian_test = np.apply_along_axis(lambda x: gaussian_train[x,:], 0, closest_cell_to_test)\n",
    "\n",
    "graph = np.load(DATA_DIR + \"adjacency_15NN.npy\")\n",
    "\n",
    "N_train_cells = len(graph)\n",
    "N_test_cells = len(test_tensor)\n",
    "\n",
    "### Get Laplacian\n",
    "laplacian_all = get_laplacian_from_tome_data(train_full)\n",
    "\n",
    "### Compute eigen\n",
    "lambda_all, v_all = get_laplacian_eig_from_laplacian(laplacian_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48182232",
   "metadata": {},
   "source": [
    "## Distribution Reconstruction\n",
    "We begin with our primary evaluation, the distribution reconstruction. We're testing the following methods' reconstruction accuracy (all beginning with the binary linear combination of genes):\n",
    "1. Using a neural network to reconstruct the first 100 Laplacian eigenvalues, and then using the Laplacian eigenfunctions to reconstruct the distribution\n",
    "2. Using a neural network to reconstruct the whole transcriptome, then using the transcriptome to reconstruct a distribution over cells\n",
    "3. Using a neural network to reconstruct the whole transcriptome, then using a neural network to reconstruct the first 100 Laplacian eigenvalues, and then using the Laplacian eigenfunctions to reconstruct the distribution\n",
    "4. Using a neural network to directly reconstruct the distribution over cells\n",
    "\n",
    "We're comparing these methods to the following positive controls:\n",
    "1. Using the true first 100 principal components of the transcriptome of a cell, followed by a neural network reconstruction of the probability distribution\n",
    "2. Using the true first 100 Laplacian eigenvalues, and then using the Laplacian eigenfunctions to reconstruct the distribution\n",
    "\n",
    "And the following negative controls:\n",
    "1. A uniform distribution over cells \n",
    "2. A random distribution over cells, $p(i)\\propto R$ where $R$ is a random real number in $[0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cd1e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Models\n",
    "\n",
    "binaryToLaplacian = torch.load(MODELS_DIR + 'binaryToLaplacian.pt').eval()\n",
    "binaryToTome = torch.load(MODELS_DIR + 'binaryToTomeNoBottleneck.pt').eval()\n",
    "tomeToLaplacian = torch.load(MODELS_DIR + 'tomeToLaplacian.pt').eval()\n",
    "binaryToGaussian = torch.load(MODELS_DIR + 'binaryToGaussian.pt').eval()\n",
    "tomeToGaussian = torch.load(MODELS_DIR + 'tomeToGaussian.pt').eval()\n",
    "PCA2Gaussian = torch.load(MODELS_DIR + 'PCAToGaussian.pt').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "baa1892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Methods\n",
    "toGraph = lambda X: np.apply_along_axis(lambda y: laplacian_coefficients_to_probability(y, v_all), 1, X)\n",
    "toTensor = lambda x: torch.tensor(x).float()\n",
    "\n",
    "def transform(X, transforms):\n",
    "    d = torch.clone(X)\n",
    "    for transform in transforms:\n",
    "        d = transform(d)\n",
    "    return d\n",
    "\n",
    "def transform_and_compute_error(X, Y, transforms, error):\n",
    "    ## Returns the final reconstruction and the error\n",
    "    d = transform(X, transforms)\n",
    "    return d, error(Y, d)\n",
    "\n",
    "# Using a neural network to reconstruct the first 100 Laplacian eigenvalues\n",
    "# Then using the Laplacian eigenfunctions to reconstruct the distribution\n",
    "dist_one = [binaryToLaplacian, toGraph]\n",
    "\n",
    "# Using a neural network to reconstruct the whole transcriptome\n",
    "# Then using the transcriptome to reconstruct a distribution over cells\n",
    "dist_two = [binaryToTome, tomeToGaussian]\n",
    "\n",
    "# Using a neural network to reconstruct the whole transcriptome \n",
    "# Then using a neural network to reconstruct the first 100 Laplacian eigenvalues\n",
    "# Then using the Laplacian eigenfunctions to reconstruct the distribution\n",
    "\n",
    "dist_three = [binaryToTome, tomeToLaplacian, toGraph]\n",
    "\n",
    "# Using a neural network to directly reconstruct the distribution over cells\n",
    "\n",
    "dist_four = [binaryToGaussian]\n",
    "\n",
    "### Positive controls\n",
    "train_pca = np.load(DATA_DIR + 'train_100_pca.npy')\n",
    "test_pca = train_pca[closest_cell_to_test,:]\n",
    "test_pca = toTensor(test_pca)\n",
    "\n",
    "test_laplacian_coeffs = np.array([get_laplacian_coefficients(gaussian_test[i,:], \n",
    "                                                      v_all)[:100] for i in range(len(gaussian_test))])\n",
    "test_laplacian_coeffs = toTensor(test_laplacian_coeffs)\n",
    "\n",
    "### Negative controls\n",
    "\n",
    "nc_one = np.ones(N_train_cells) / N_train_cells\n",
    "nc_one = np.tile(nc_one, (N_test_cells, 1))\n",
    "nc_one = toTensor(nc_one)\n",
    "\n",
    "nc_two = np.random.rand(N_test_cells, N_train_cells)\n",
    "row_sums = nc_two.sum(axis=1)\n",
    "nc_two = nc_two / row_sums[:, np.newaxis]\n",
    "nc_two = toTensor(nc_two)\n",
    "del row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61385331",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ### Methods\n",
    "    one, one_error = transform_and_compute_error(test_binary_tensor, gaussian_test, \n",
    "                                            dist_one, cross_entropy_on_matrix)[1]\n",
    "\n",
    "    two, two_error = transform_and_compute_error(test_binary_tensor, gaussian_test, \n",
    "                                            dist_two, cross_entropy_on_matrix)[1]\n",
    "    \n",
    "    three, three_error = transform_and_compute_error(test_binary_tensor, gaussian_test, \n",
    "                                            dist_three, cross_entropy_on_matrix)[1]\n",
    "    \n",
    "    four, four_error = transform_and_compute_error(test_binary_tensor, gaussian_test, \n",
    "                                            dist_four, cross_entropy_on_matrix)[1]\n",
    "    \n",
    "    ### Positive controls\n",
    "    pc_one, pc_one_error = transform_and_compute_error(test_pca, gaussian_test, [PCA2Gaussian], \n",
    "                                               cross_entropy_on_matrix)[1]\n",
    "    \n",
    "    pc_two, pc_two_error = transform_and_compute_error(test_laplacian_coeffs, gaussian_test, \n",
    "                                         [toGraph], cross_entropy_on_matrix)[1]\n",
    "    \n",
    "    ### Negative controls\n",
    "    nc_one, nc_one_error = cross_entropy_on_matrix(nc_one, gaussian_test)\n",
    "    \n",
    "    nc_two, nc_two_error = cross_entropy_on_matrix(nc_two, gaussian_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4706d0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [\"M1\", 'M2', 'M3', 'M4', 'PC1', 'PC2', 'NC1', 'NC2']\n",
    "errors = [one_error, two_error, three_error, four_error, pc_one_error, pc_two_error, nc_one_error, nc_two_error]\n",
    "plt.bar(labels, errors)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acd0c91",
   "metadata": {},
   "source": [
    "| Method Code | Description                                           |\n",
    "|-------------|-------------------------------------------------------|\n",
    "| M1          | NN Reconstruction of 100 Laplacian Coeff.             |\n",
    "| M2          | NN T-ome Reconstruction, then NN Dist. Reconstruction |\n",
    "| M3          | NN T-ome Reconstruction -> NN Laplacian Coeff.        |\n",
    "| M4          | NN Dist. Reconstruction                               |\n",
    "| PC1         | Positive Control: 100 PC Loadings                     |\n",
    "| PC2         | Positive Control: 100 Laplacian Coeff.                |\n",
    "| NC1         | Negative Control: Uniform Dist.                       |\n",
    "| NC2         | Negative Control: Random Dist.                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf6c508",
   "metadata": {},
   "source": [
    "## Transcriptome Reconstruction\n",
    "Next is our secondary evaluation, the transcriptome reconstruction, using mean squared error loss. We're testing the following methods' reconstruction accuracy (all beginning with the binary linear combination of genes):\n",
    "1. Using a neural network to reconstruct the first 100 Laplacian eigenvalues, then using the Laplacian eigenfunctions to reconstruct the distribution, then taking a weighted average of the transcriptomes of cells in the distribution\n",
    "2. Using a neural network to reconstruct the first 100 Laplacian eigenvalues, then using a neural network to reconstruct the whole transcriptome\n",
    "3. Using a neural network to directly reconstruct the whole transcriptome\n",
    "4. Using a bottlenecked neural network to reconstruct the whole transcriptome\n",
    "\n",
    "We're comparing these methods to the following positive controls:\n",
    "1. The ground truth transcriptome with multivariate Gaussian noise, with standard deviation calculated from each gene's expression levels\n",
    "1. Using the true first 100 principal components of the transcriptome of a cell, followed by a neural network reconstruction of the transcriptome\n",
    "2. Using the true first 100 Laplacian eigenvalues, followed by a neural network reconstruction of the transcriptome\n",
    "\n",
    "And the following negative controls:\n",
    "1. The average transcriptome of all cells on the graph\n",
    "2. A random transcriptome drawn from a multivariate Gaussian centered on the average transcriptome with standard deviation calculated from each gene's expression levels\n",
    "3. A random cell's transcriptome drawn from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdedebd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2634e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587311c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea023bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f18760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd0db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb2435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d58624d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rna_sensor] *",
   "language": "python",
   "name": "conda-env-rna_sensor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
